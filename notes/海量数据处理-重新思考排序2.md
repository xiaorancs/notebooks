## 海量数据处理－－重新思考排序(2)
> 如今互联网产生的数据量已经达到PB级别，如何在数据量不断增大的情况下，依然保证快速的检索或者更新数据，是我们面临的问题。在之前我们也提到过，然而在大数据处理的技术中，排序起到很重要的作用，可能不是直接使用，要不使用这用划分的思想，或者在小的方面使用到排序的方法，例如在在我们之前提到的Top k问题，用用到了堆排序中堆，在上一节介绍堆排序额时候，我们也给出了一个使用最大堆的例子。本篇文章，我们继续讨论排序。

### 闲话少叙，进入主题
今天我们主要讨论归并排序，快速排序，桶排序，计数排序，他们的思想已经我们会怎么用到这用思想，还有一点他们的扩张，我们尽量将这些方法使用在大数据处理上。上篇文章提到过的排序的方法，读者有兴趣的话可以自己学习。对这四种排序方式，我都会总结一句话，表达它的思想。   
+ 归并排序，分而治之，先排后归。
+ 快速排序，以轴划分，左右并行。
+ 桶排序， 划分进桶，桶中排序。
+ 计数排序，确定范围，填充位置。

### 归并排序
> 归并排序: 建立在归并操作上的一种排序算法，该方法采用分治法的一个非常典型应用，一般我们都是使用二路归并，就是将数据划分成两部分进行处理，但是注意我们可以是多路归并，不要让二路归并排序限制我们的思想。
>  从下面的伪代码中，我们可以很容易看到二路归并排序只有两个部分，一个是递归划分，一个是归并操作，这就是我们最长用到的归并排序。但是在海量数据的排序过程中，我们可以使用二路归并，当然我也可以选择多路归并排序。

**伪代码:**
```
// 归并
merge(array, left, mid, right):
    tmp = new int[right - left + 1] // 申请复制空间
    i = left, j = mid+1, k = 0;
    while(i <= mid && j <= right) {
        if(array[i] < array[j]) tmp[k++] = array[i++];
        else tmp[k++] = array[j++];
    }
    // 处理尾部，可能会有一部分没有处理结束
    while(i <= mid) tmp[k++] = array[i++];
    while(j <= right) tmp[k++] = array[j++];
    
    // copy回到原来的数据, tmp -> array
    copy(array[left, right], tmp[0,k-1])

// 调用
merge_sort(array, left, right):
    if(left < right) {
        mid = (left + right) / 2;
        merge_sort(array, left, mid);
        merge_sort(array, mid+1, right);

        // 调用归并函数
        merge(arr, left, mid, right);
    }

```

海量数据排序，使用归并排序的思想进行排序，例如我们现在有一个5G的数据文件，每一行有一个32位的正整数，现在要求只能使用1G的内存空间，对这个文件排序。
我们有大数据处理的经验都知道，内存放不下，只能将大文件分成几个小文件，这就是划分，之后对每个文件进行排序，最后归并这几个小文件的排序结果，叫做多路归并。上述的过程可以叫做外排序，即借助外部的文件进行排序。
> 从这个题目出发我们使用之前介绍过的大数据处理技术完成这个排序过程。    
> 1. 划分成5个小文件，5G / 1G = 5
> 2. 将单个文件读入内存，进行排序，写入文件
> 3. 使用5路归并，将每个文件作为一路排序，归并最后得到结果  

<center> <a href="https://ibb.co/ma0ifA"><img src="https://image.ibb.co/hzxktV/Screenshot-from-2018-11-07-17-49-48.png" alt="Screenshot-from-2018-11-07-17-49-48" border="0"></a> </center>


> 在上述的问题中，我们使用归并排序的思想加数据结构堆来进行了大文件的排序。我们都知道多次的读写文件是很浪费时间的，能不能进行优化呢？有一个条件没有使用到，那就是所有数字都是32的正整数。我们可以知道数据的范围[0-2^32-1].还记得计数排序，确定范围，填充位置。

### 计数排序




